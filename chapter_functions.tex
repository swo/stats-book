%!TEX root = main.tex

\chapter{Functions}
\label{chapter:functions}

It may seem weird to start a book about statistics with something as abstract
as ``functions'', but I think that probability theory becomes very confusing if you
are not entirely comfortable with the formalism of mathematical functions.

As an example, as they are typically meant in statistical writing, $x=2$ is a
true or false statement, while $X=2$ is an \emph{event}, which we will define
later. This distinction often causes enormous confusion. After reading this
chapter, you should comfortable with the idea that the ``equals'' sign in the
statements $x=2$ and $X=2$ are actually different functions.

\section{Functions map things to other things}

In mathematical terms, a \emph{function} is relationship between sets, linking
each element of one set to an element of another set. For example, say I have a
function $f$ that links each number to the that number plus one:
\begin{gather*}
f(1) = 2 \\
f(2) = 3 \\
\text{etc.}
\end{gather*}
This function is relatively simple in that it has only one input and it links
elements of a set, the integers, onto other members of the same set. As we will
see, functions can be much more complicated than this.

For many people, especially those used to computer programming, it may be more
natural to think of a function as a factory: $f$ ``takes'' an input number $x$,
adds $1$ to $x$, and then ``returns'' the output $x+1$. This analogy can be
confusing because, in computer science, a ``function'' can actually refer to
different things. The correct analogy to the mathematical concept of
``function'' is called a ``pure'' function in computer science, where ``pure''
means that the function is guaranteed to produce the same output whenever given
the same input.\footnote{A pure function also has no ``side effects'', which
means that calling that function cannot change anything about the statement of
the program.} For example, a random number generator, while it might be called
a ``function'' in a program, is not a pure function. To the user's eye, a
random number generator is called multiple times, with no input, and returns
different numbers every time.

Some functions, like my example above, map one number to another, single
number. Other functions take two numbers and return one number. For example, say
the function $g$ adds two numbers:
\begin{equation*}
g(1, 2) = 3
\end{equation*}
In fact, this is just the ``plus'' function that we usually write with \emph{infix
notation}, meaning that we put the operator between the arguments, like $1+2$,
rather than at the front, like $\mathord{+}(1, 2)$.

A function can take something that is not a number and return a number. For
example, say the determinant of a matrix $A$ is $5$:
\begin{equation*}
\mathrm{det}(A) = 5
\end{equation*}
The reverse is of course possible. For example, a function could take as input
a positive integer and return the identity matrix of that size:
\begin{equation*}
    \mathrm{Identity}(3) = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ \end{bmatrix}
\end{equation*}

Or a function can take numbers and return something that is not a number. For
exmaple, the statement ``$5$ is less than or equal to $2$'' is false: the
operator ``less than or equal two'' takes two numbers ($5$ and $2$) and returns
a Boolean value (``false'').

A function can also take a function as input and return a number. For example,
the minimum of the function $f(x) = x^2$ is zero. A function (``minimum'') took
a function ($f$) as input and returned a number (zero).

A function can also take a function and return a different function. For
example, the mirror of $f(x)$ around the $x=0$ point is a new function $g(x) =
f(-x)$. The function ``mirror around $x=0$'' took a function ($f$) as input and
returned another function ($g$). In computer science, functions that return
functions are sometimes called ``function factories''.

I hope it's clear that the inputs or outputs could be anything. I could even
say that I have a function $h$ that maps from the space of quadrilaterals to
the space of vegetables:
\begin{equation*}
h(\lozenge) = \text{Brussels sprouts}.
\end{equation*}
There is a special notation to make it clear what kinds of spaces a function
maps from and to:
\begin{equation*}
h : \text{quadrilaterals} \to \text{vegetables}.
\end{equation*}
Perhaps more familiar, the function $f$ above maps from real numbers to other
real numbers:
\begin{equation*}
f : \mathbb{R} \to \mathbb{R}
\end{equation*}
Functions with multiple inputs, like $g$ above, get a Cartesian product
``cross'':
\begin{equation*}
g : \mathbb{R} \times \mathbb{R} \to \mathbb{R}
\end{equation*}



\section{Functions are written in different ways}

Confusingly, we write functions in many different ways. The most obvious is the
``prefix'' or ``Eulerian'' style, where single-letter, italic text functions or
3-ish-letter, normal text functions precede their inputs:
\begin{gather*}
f(1) = 2 \\
\sin \pi = 1 \\
\mathrm{add}(1, 2) = 3
\end{gather*}



Sometimes the ``dot'' notation, like $f(\cdot)$, is used to distinguish the
function $f$ from the number $f(x)$ that the function outputs for the input
$x$. The dot avoids the confusion about whether $x$ is a stand-in or whether it
is an actual number by using the dot, which is clearly not a number.

But sometimes we write certain functions of two inputs with an ``infix'' style
in between the two inputs: we write $1 + 2 = 3$ rather than $\mathord{+}(1, 2)
= 3$. In a few cases, we write a function as ``around-fix''. For example, the
determinant of the matrix $A$ is often written $|A|$. We even use a ``postfix''
for things the factorial function: $4! = 24$.

Don't be alarmed. These are all just functions, mappings from one set of things
to another set of things. If you see some notation you do not understand, ask,
``What is this a function of? What kinds of things is it mapping from and to?''

\section{Different functions are written in the same way}

Computer scientists are likely comfortable with \emph{polymorphism}, the
notion that the same ``function'', applied to different inputs, takes different
actions. For example, in many programming languages, \texttt{+} is both
numeric addition and string concatenation: \texttt{1 + 2} returns \texttt{3},
but \texttt{"Stats " + "rules"} gives \texttt{"Stats rules"}. Somehow the
``function'' \texttt{+} knew to add in one case and to concatenate in the
other.

We do the same thing with fairly common symbols, like ``equals'' ($=$). For
example, say $f(x) = x^2$. Then $f(2) = 4$ is true but $f(2) = 5$ is false.
The ``equals'' in $f(2) = 5$ is a function that takes two numbers, $f(2)$ and
$5$, and returns the Boolean ``false''. Extra confusingly, the ``equals'' in
$f(x) = x^2$ is not a function at all; it is a signal to you, the reader, that
a function is being defined! I try to avoid this confusion in this book by
writing ``def'' on top of any equal sign that is a mathematically important
definition.

Polymorphism arises in a few critical and very confusing moments in probability
theory. For example, if I say ``the probability that $X$ equals two'', you will
respond with a number between zero and one. Say the value is one-third:
\begin{equation*}
\prob{X = 2} = \tfrac{1}{3}
\end{equation*}
Apparently, ``probability'' is a function that maps statements like
``$X$ equals two'' to a number:
\begin{equation*}
\mathbb{P} : \text{statements like ``$X=2$''} \to [0, 1]
\end{equation*}
Now if I say, ``the probability that one equals two'', you will say ``zero'':
\begin{equation*}
\prob{1 = 2} = 0
\end{equation*}
This makes it seem like ``$X=2$'' and ``$1=2$'' are the same
kinds of statements.

However, in another sense, ``one equals two'' is clearly ``false'', but
``the probability of false is zero'' doesn't make a lot of sense. The probability
function does not take Booleans; it takes something called \emph{events} that
will be defined in the next chapter. The point is that the ``equals'' in ``$X=2$''
means a different thing from the ``equals'' in ``$1=2$'', since ``$X=2$'' need
not resolve to simply ``true'' or ``false''.
